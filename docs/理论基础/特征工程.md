# 特征工程

特征工程是机器学习中的一个重要步骤，它涉及到对原始数据进行处理和转换，以提取出对模型性能有重要影响的特征。特征工程的目标是提高模型的准确性和泛化能力，同时减少模型的复杂度和计算成本。

## 数据预处理

* 在获取的数据中经常会遇到唯一属性，这些属性通常是人为添加的一些`id`属性，如存放在数据库中的自增的主键
  * 对于这些属性，它并不能刻画样本自身的分布规律。所以只需要简单的删除这些属性
* 对于数据中的某个属性，如果其方差很小，则意味着**其识别能力较弱**。极端情况下其方差为$0$，这意味着该属性在所有样本上的值都是恒定的
  * 因此可以设定一个阈值（如 $10^{-3}$ ），将方差小于该阈值的属性直接剔除

### 缺失值处理

缺失值处理一般有三种处理方式：
* **不处理**
  * 某些算法可以直接使用含有缺失值的情况，如决策树算法可以直接使用含有缺失值的数据
* **删除含有缺失值的样本**
  * 如果样本中的缺失值较少，则直接丢弃样本会损失大量的有效信息
* **填充缺失值**
  * 计算复杂，而且当插补的值估计不准确时，会对后续的模型引入额外的误差

#### 均值插补

* 对于**连续型属性**，可以使用**均值**进行插补
* 对于**离散型属性**，可以使用**众数**进行插补

#### 建模预测

建模预测的思想是：**将缺失的属性作为预测目标，通过建立模型来预测**

将未含有缺失值的样本作为新的训练集，标签值重新定义为属性 $j$ 的值，通过建模来完成属性 $j$ 的学习。将含有缺失值的样本作为测试集，通过学得的模型来预测其属性 $j$ 的值

这种方法的效果相对较好，但是该方法有个根本缺陷:
* 如果其他属性和属性 $j$ 无关，则预测的结果无意义
* 如果预测结果相当准确，则又说明属性 $j$ 可以由其它属性计算得到， 于是属性 $j$ 信息冗余，没有必要纳入数据集中

### 异常值处理

异常值是拥有与数据集中大部分数据显著不同特征的数据对象
* 一些离群点会干扰数据分析，是需要去除的
* 另外一些离群点则会是数据挖掘的分析对象
  * 信用卡欺诈
  * 网络入侵

#### 异常值检测

1. **箱线图**

箱线图被广泛用于检测和识别数据中的异常值 (离群点)，箱线图中，箱体的上下边缘分别表示 $75\%$ 分位点 $Q_3$ 和 $25\%$ 分位点 $Q_1$ ，箱体中间的线表示中位数 $Q_2$ 

箱体上方和下方的虚线（最大值和最小值）引出了可能存在的异常值。异常值可以基于以下的方法计算

* 上边缘：$Q_3+1.5\times IQR$
* 下边缘：$Q_1-1.5\times IQR$

其中 $IQR=Q_3-Q_1$, 在箱线图中, 位于上下边缘以外的点被认为是离群点, 并被认为是异常值

2. `Z-score`方法

在正态分布下,  $99.7\%$的数据位于$[\mu-3\sigma, \mu+3\sigma]$之间，而小**概率事件在一次试验中不可能发生**, 因此在这个区间外的数据可被视为离群点

3. `Tukey’s method`

`Tukey's method`是一种常用的识别离群值的方法，以中位数和四分位数为基础来识别离群点

数据位于 $[Q_1-k\times IQR, Q_1+k\times IQR]$ 之外的为离群点，其中 $k$ 值应根据数据集而定，通常取 $1.5$, $IQR$ 为四分位距

4. **调整的箱型图方法**

* `Z-score` 和 `Tukey’s method` 方法均适用于数据对称情形, 如果数据有偏度(skewness),需要考虑偏度的影响
* 定义 MC（mdcouple），衡量偏度的指标
$$
\underset{x_i\le Q_2\le x_j}{\text{median}}\,\,h\left( x_i, x_j \right) \qquad \text{其中}Q_2\text{为中位数} \\
h(x_i, x_j)=\frac{(x_j-Q_2)-(Q_2-x_i)}{x_j-x_i}
$$
* 正常数据区间

$$
\begin{cases}
	\left[ Q_1-1.5e^{-4MC}IQR, Q_3+1.\mathbf{5}e^{3MC}IQR \right] , MC>0\\
	\left[ Q_1-1.5e^{-3MC}IQR, Q_3+1.\mathbf{5}e^{4MC}IQR \right] , MC<0\\
\end{cases}
$$

## 特征编码

### one-hot编码

### 离散化

## 数据标准化、正则化

### 标准化

### 正则化

## 特征选择

### 过滤

### 包装

### 嵌入

## 稀疏表示与字典学习

## 多分类问题

## 样本类别不平衡问题

### 欠采样

### 过采样

### 混合采样
